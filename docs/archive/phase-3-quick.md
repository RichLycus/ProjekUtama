# ğŸ¯ Phase 3 Quick Reference - AI Chat Integration

## ğŸ“‹ Executive Summary

**Goal**: Implement professional 5-Core RAG system for local LLM chat  
**Stack**: Ollama + Llama3:8B + ChromaDB + SQLite  
**Architecture**: Multi-Agent Pipeline (Router â†’ RAG â†’ Execution â†’ Reasoning â†’ Persona)

---

## ğŸ—ï¸ System Architecture (One-Page)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      USER INPUT                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AGENT 1: ROUTER / INTENT CLASSIFIER                       â”‚
â”‚ â€¢ Analyze: "Is this code/creative/tool request?"          â”‚
â”‚ â€¢ LLM: 7B lightweight                                      â”‚
â”‚ â€¢ Output: Intent tag (code/creative/general/tool)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AGENT 2: RAG / RETRIEVAL ENGINE                           â”‚
â”‚ â€¢ Fetch: Tool schemas, Golden Rules, Past convos          â”‚
â”‚ â€¢ Source: Vector DB (ChromaDB) + SQLite                   â”‚
â”‚ â€¢ Output: Relevant context (3-5 sources)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AGENT 3: EXECUTION      â”‚   â”‚ AGENT 4: REASONING         â”‚
â”‚ â€¢ Check: Need tool?     â”‚   â”‚ â€¢ Input: User + Context +  â”‚
â”‚ â€¢ Execute: Python Tool  â”‚   â”‚   Tool Result              â”‚
â”‚ â€¢ API: POST /tools/exec â”‚   â”‚ â€¢ LLM: 7B full power       â”‚
â”‚ â€¢ Output: Result/Error  â”‚   â”‚ â€¢ Output: Raw answer       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â†“
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚ AGENT 5: PERSONA / TONE FORMATTER     â”‚
                â”‚ â€¢ Apply: Lycus (Tech) / Polar (Art)   â”‚
                â”‚ â€¢ LLM: 7B light                        â”‚
                â”‚ â€¢ Output: Final styled response        â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â†“
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚  FINAL OUTPUT    â”‚
                        â”‚  (to User UI)    â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¨ UI Components Map

### ChatPage (`/chat`)
```
â”œâ”€â”€ AvatarDisplay.tsx           // Left panel: 3D avatar (future Vroid)
â”œâ”€â”€ AgentStatusPanel.tsx        // Show which agent is active
â”œâ”€â”€ ChatContainer.tsx           // Main chat area
â”‚   â”œâ”€â”€ ChatMessage.tsx         // Individual message bubble
â”‚   â””â”€â”€ ExecutionLog.tsx        // Show RAG/Tool steps
â””â”€â”€ ChatInput.tsx               // Bottom: input + send button
```

### SettingsPage (`/settings`)
```
â””â”€â”€ AI Chat Tab (NEW)
    â”œâ”€â”€ CoreModelSetup           // Ollama URL, model selection
    â”œâ”€â”€ RAGConfiguration         // Vector DB, context size
    â””â”€â”€ PersonaControl           // Default persona, exec policy
```

---

## ğŸ—ƒï¸ Database Schema (Quick)

```sql
-- Conversations
conversations: id, title, persona, created_at, updated_at

-- Messages
messages: id, conversation_id, role, content, agent_tag, 
          execution_log, timestamp

-- RAG Cache
rag_cache: id, query, context, sources, relevance_score, created_at
```

---

## ğŸ”— API Endpoints (Quick)

```
Chat:
  POST   /api/chat/message       â†’ Trigger Agent 1
  GET    /api/chat/history       â†’ Get conversation
  POST   /api/chat/clear         â†’ Clear history
  GET    /api/chat/status        â†’ Agent status

AI Config:
  POST   /api/ai/config          â†’ Update settings
  GET    /api/ai/models          â†’ List Ollama models
  POST   /api/ai/test-connection â†’ Test Ollama
```

---

## ğŸ“¦ Dependencies (Quick Install)

**Backend:**
```bash
pip install ollama chromadb sentence-transformers langchain
```

**Frontend:**
```bash
yarn add markdown-to-jsx prismjs
```

**Ollama Setup:**
```bash
# Install Ollama
curl https://ollama.ai/install.sh | sh

# Pull model
ollama pull llama3:8b

# Start server
ollama serve
```

---

## ğŸ­ Personas (Quick Guide)

### Lycus (Technical)
```
Tone: Direct, practical, code-focused
Use: Programming questions, tool requests
Color: Purple (#8b5cf6)
Example: "Here's the Python code. Use f-strings for clean formatting."
```

### Polar Nexus (Creative)
```
Tone: Inspiring, artistic, metaphorical
Use: Story ideas, design concepts
Color: Blue (#3b82f6)
Example: "Imagine your code as a canvas. Each function is a brushstroke."
```

### Sarah (Friendly) - BONUS
```
Tone: Warm, helpful, conversational
Use: General questions, guidance
Color: Pink (#ec4899)
Example: "I'd be happy to help! Let me break this down for you."
```

---

## âœ… Implementation Checklist (Minimal)

### Phase 3.1: Basic Chat (Week 1-2)
- [ ] ChatPage UI redesign
- [ ] Chat message storage (SQLite)
- [ ] Ollama client wrapper
- [ ] Settings AI tab
- [ ] Single-agent LLM test

### Phase 3.2: Multi-Agent (Week 3-4)
- [ ] Agent 1: Router
- [ ] Agent 2: RAG engine
- [ ] Agent 3: Tool bridge
- [ ] Agent 4: Reasoning
- [ ] Agent 5: Persona
- [ ] Pipeline orchestration

### Phase 3.3: Polish (Week 5-6)
- [ ] Agent status UI
- [ ] Execution logs
- [ ] Mobile responsive
- [ ] Error handling
- [ ] Testing

---

## ğŸš€ Quick Start Commands

```bash
# 1. Install Ollama & pull model
ollama pull llama3:8b

# 2. Install Python deps
cd backend && pip install -r requirements.txt

# 3. Initialize RAG database
python backend/ai/init_rag.py

# 4. Start backend
uvicorn server:app --reload --port 8001

# 5. Start frontend
cd .. && yarn vite --config vite.config.web.ts

# URLs
Frontend: http://localhost:5173/chat
Backend:  http://localhost:8001
Ollama:   http://localhost:11434
```

---

## ğŸ¯ Success Metrics

**Functional:**
- âœ… Chat works end-to-end
- âœ… RAG retrieves relevant context
- âœ… Tools execute correctly
- âœ… Persona applied consistently

**Performance:**
- âœ… Response < 5 seconds
- âœ… RAG retrieval < 500ms
- âœ… UI 60fps responsive

**Quality:**
- âœ… Accurate answers
- âœ… No hallucinations
- âœ… Proper context usage

---

## ğŸ“š Key Files Reference

```
Backend:
  backend/ai/agents.py              â†’ 5 Agent classes
  backend/ai/rag_engine.py          â†’ RAG logic
  backend/ai/ollama_client.py       â†’ Ollama wrapper
  backend/routes/chat_routes.py     â†’ Chat API

Frontend:
  src/pages/ChatPage.tsx            â†’ Main chat UI
  src/components/chat/              â†’ Chat components
  src/store/chatStore.ts            â†’ Chat state

Docs:
  docs/phase/phase-3.md             â†’ Full planning doc
  docs/phase/phase-3-quick.md       â†’ This file
```

---

## ğŸ› Common Issues & Solutions

**Issue**: Ollama connection refused  
**Fix**: `ollama serve` & check http://localhost:11434

**Issue**: RAG not finding context  
**Fix**: Run `python backend/ai/init_rag.py` to index

**Issue**: Slow responses  
**Fix**: Use smaller model (mistral:7b or phi-2)

**Issue**: Out of memory  
**Fix**: Reduce context size in settings (2000 tokens)

---

## ğŸ“ Learning Resources

- [Ollama Docs](https://ollama.ai/docs)
- [ChromaDB Guide](https://docs.trychroma.com/)
- [LangChain RAG](https://python.langchain.com/docs/use_cases/question_answering/)
- [Multi-Agent Systems](https://arxiv.org/abs/2308.08155)

---

**Made with â¤ï¸ for ChimeraAI**  
**Version**: Phase 3 Planning  
**Last Updated**: October 2025
